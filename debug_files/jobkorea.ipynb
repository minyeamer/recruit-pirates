{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잡코리아 데이터 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(company: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아에서 회사 이름에 대한 검색 결과 페이지를 반환하는 함수\n",
    "    company: 잡코리아에서 검색할 회사 이름\n",
    "    source: 잡코리아 회사 검색 결과 페이지, 함수 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://www.jobkorea.co.kr/Search/?stext={company}&tabType=corp'\n",
    "    \n",
    "    web = requests.get(url).content\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_url(source: BeautifulSoup) -> str:\n",
    "    \"\"\"\n",
    "    잡코리아 회사 검색 결과 페이지에서 가장 상단에 있는 회사의 페이지 주소를 반환하는 함수\n",
    "    source: 잡코리아 회사 검색 결과 페이지\n",
    "    company_url: 잡코리아 회사 정보 페이지 주소, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    corp_info = source.find('div', {'class': 'corp-info'})\n",
    "    corp_list = corp_info.find('li', {'class': 'list-post'})\n",
    "    corp_name = corp_list.find('a', {'class': 'name'})\n",
    "\n",
    "    company_url = 'https://www.jobkorea.co.kr' + corp_name.get('href')\n",
    "\n",
    "    return company_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assay_dict(company_url: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 자소서 목록을 반환하는 함수\n",
    "    url: 잡코리아 회사 정보 페이지 주소\n",
    "    assay_dict: {'자소서 제목': '자소서 페이지 번호'}, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    assay_url = company_url + '/PassAssay'\n",
    "    \n",
    "    web = requests.get(assay_url).content\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "\n",
    "    assay_dict = dict()\n",
    "\n",
    "    assay_div = source.find('div', {'class': 'passassayCont'})\n",
    "    \n",
    "    try:\n",
    "        assay_list = assay_div.find_all('li', {'class': 'assay'})\n",
    "    except AttributeError:\n",
    "        return assay_dict\n",
    "\n",
    "    for assay in assay_list:\n",
    "        assay_title = assay.find('h2', {'class': 'tit'}).get_text().strip()\n",
    "        assay_url = assay.find('a').get('href').split('&Part_Code=')[0]\n",
    "        assay_number = assay_url.split('Job_Epil_No=')[1]\n",
    "        assay_dict[assay_title] = assay_number\n",
    "\n",
    "    return assay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assay_detail(company_url: str, assay_info: tuple) -> dict:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지의 모든 내용을 반환하는 함수\n",
    "    assay_detail: 합격자소서 페이지의 모든 내용을 담은 딕셔너리, 반환값\n",
    "\n",
    "    !!! 에러 발생 !!!\n",
    "    합격자소서 페이지 요청 시 body가 자바스크립트 코드 안에 포함되어 반환\n",
    "    클래스가 detailView인 article 태그를 찾아낼 수 없음\n",
    "    \"\"\"\n",
    "\n",
    "    assay_title = assay_info[0]\n",
    "    assay_number = assay_info[1]\n",
    "    assay_detail = {'Title': assay_title}\n",
    "\n",
    "    url = company_url + f'/PassAssay/View?Job_Epil_No={assay_number}'\n",
    "    \n",
    "    web = requests.get(url).content\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "\n",
    "    detail_view = source.find('article', {'class': 'detailView'})\n",
    "\n",
    "    assay_detail['Index'] = get_assay_index(detail_view)\n",
    "\n",
    "    qna_contents = get_qna_contents(detail_view)\n",
    "\n",
    "    for i in range(len(qna_contents)):\n",
    "        assay_detail[f'Q{i+1}'] = qna_contents[i]\n",
    "\n",
    "    try:\n",
    "        assay_detail['Advice'] = get_advice_contents(detail_view)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    return assay_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assay_index(detail_view: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 목차 목록을 반환하는 함수\n",
    "    index_list: 합격자소서 페이지의 목차 목록, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    index_div = detail_view.find('div', {'class': 'bx'})\n",
    "    \n",
    "    index_li = index_div.find_all('li')\n",
    "    index_list = [index.get_text().strip() for index in index_li]\n",
    "    \n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qna_contents(detail_view: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 목차 목록을 반환하는 함수\n",
    "    qna_contents: 합격자소서 페이지의 질문과 답변, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    qna_div = detail_view.find('div', {'class': 'selfQnaWrap'})\n",
    "    qna_titles = qna_div.find_all('dt', {'class': 'on'})\n",
    "    qna_shows = qna_div.find_all('dd', {'class': 'show'})\n",
    "    qna_contents = []\n",
    "\n",
    "    for qna_title, qna_show in zip(qna_titles, qna_shows):\n",
    "        qna_title = qna_title.find('span', {'class': 'tx'}).get_text()\n",
    "        qna_lines = qna_show.find_all('b')\n",
    "        if not qna_lines:\n",
    "            qna_lines = qna_show.find('div', {'class': 'tx'})\n",
    "\n",
    "        lines = []\n",
    "        for qna_line in qna_lines:\n",
    "            lines += re.split('\\.\\s', qna_line.get_text().strip())\n",
    "        qna_lines = lines\n",
    "\n",
    "        # qna_lines = []\n",
    "        # for line in lines:\n",
    "        #     if not any(x not in line for x in ['좋은점', '아쉬운점', '글자수']):\n",
    "        #         qna_lines.append(line)\n",
    "        \n",
    "        qna_contents.append({qna_title: qna_lines})\n",
    "    \n",
    "    return qna_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advice_contents(detail_view: BeautifulSoup) -> tuple:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 총평 내용을 반환하는 함수\n",
    "    advice_contents: 합격자소서 페이지의 총평 내용, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    advice_div = detail_view.find('div', {'class': 'adviceTotal'})\n",
    "\n",
    "    # advice_title = advice_div.find('h4', {'class': 'tit'}).get_text().strip()    \n",
    "    advice_grade = advice_div.find('span', {'class': 'grade'}).get_text().strip()\n",
    "\n",
    "    advice_lines = advice_div.find('p', {'class': 'tx'}).get_text()\n",
    "    advice_lines = advice_lines.replace(' \\r\\n\\r\\n', ' ')\n",
    "    advice_lines = advice_lines.replace('\\r\\n\\r\\n', ' ')\n",
    "    advice_lines = re.split('\\.\\s', advice_lines)\n",
    "    \n",
    "    return advice_grade, advice_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_assay(original_dict: dict) -> tuple:\n",
    "    \"\"\"\n",
    "    딕셔너리에서 하나의 키값을 선택해서 해당 키와 값을 반환하는 함수\n",
    "    assay_dict: {'자소서 제목': '자소서 페이지 번호'}\n",
    "    select_page: {'인덱스': ('자소서 제목', '자소서 페이지 번호')}, 반환값\n",
    "    \"\"\"\n",
    "    \n",
    "    assay_dict = original_dict.copy()\n",
    "    index, selection = 1, None\n",
    "\n",
    "    while True:\n",
    "        select_page = dict()\n",
    "\n",
    "        try:\n",
    "            for i in range(10):\n",
    "                select_page[index] = assay_dict.popitem()\n",
    "                index += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        for idx, assay in select_page.items():\n",
    "            print(f'{idx}. {assay[0]}')\n",
    "        \n",
    "        if assay_dict:\n",
    "            print('다음 페이지로 이동(n)')\n",
    "            selection = input('목록을 선택해주세요. ')\n",
    "            if selection == 'n':\n",
    "                continue\n",
    "            return select_page[int(selection)]\n",
    "        else:\n",
    "            print('마지막 페이지 입니다.')\n",
    "            selection = input('목록을 선택해주세요. ')\n",
    "            return select_page[int(selection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_jobkorea():\n",
    "    \"\"\"\n",
    "    잡코리아 크롤링 실행 함수\n",
    "    현재 반환값: assay_detail\n",
    "    \"\"\"\n",
    "\n",
    "    company = input('회사 이름을 입력하세요. ')\n",
    "\n",
    "    try:\n",
    "        source = get_source(company)\n",
    "        company_url = get_company_url(source)\n",
    "    except AttributeError or ConnectionError:\n",
    "        raise Exception('회사 이름이 올바르지 않습니다.')\n",
    "    \n",
    "    assay_dict = get_assay_dict(company_url)\n",
    "\n",
    "    if not assay_dict:\n",
    "        print('합격자소서가 없습니다.')\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        selection = select_assay(assay_dict)\n",
    "    except KeyError or ValueError:\n",
    "        raise Exception('잘못된 번호를 입력하셨습니다.')\n",
    "    \n",
    "    assay_detail = get_assay_detail(company_url, selection)\n",
    "    print(assay_detail)\n",
    "    \n",
    "    # 작성 중"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [지원 동기: 함께하고 싶습니다]\n",
      "2. 지원동기 및 입사후 포부\n",
      "마지막 페이지 입니다.\n",
      "{'Title': '[지원 동기: 함께하고 싶습니다]', 'Index': ['Q1. [지원 동기: 함께하고 싶습니다]', 'Q2. [직무역량: 회원관리, 이미 실무 준비는 끝났습니다]'], 'Q1': {'[지원 동기: 함께하고 싶습니다]': ['앞으로의 행보가 더욱 기대되는 직방에 저의 역량을 보여 드려 도움을 드리고, 직방이 불확실한 대한민국 기업 시장에서 고영양가의 뿌리를 내릴 수 있도록 힘쓴 선배들에게 많은 배움을 받고 싶어 지원하게 되었습니다.', '저는 평소 어떤 일을 함에 있어 항상 나름의 호구지책을 마련하고 일을 하는 편입니다', '즉, 안정적으로 업무를 수행하는 것을 선호한다는 것입니다', '이런 상황에서 몇 년 전부터 대한민국에서 쏟아져 나왔던 스타트업 기업에 대한 기사들을 많이 보게 되었습니다', '불확실한 미래에서도 자신의 아이디어를 펼치기 위해 노력하는 스타트업 멤버들이 대단했지만, 무엇보다 존경스러웠던 점은 꾸준히 업을 유지하고 있다는 것입니다', ' 이처럼 개인의 삶에서 성공하고 있는 사람들을 보며 그들을 벤치마킹해 삶의 태도를 수정하고 있습니다', '나름 도전적인 목표를 설정하며 적극적인 삶을 살고 있지만, 성숙한 태도를 갖기에는 아직 부족한 면이 있다고 생각합니다', ' 직방에 입사 후 회원관리팀에서 저의 젊은 패기를 기반으로 적극적으로 아이디어를 제안하며 팀의 발전에 도움을 드릴 것이며, 먼저 사회에 뛰어든 선배님들께 미래 스타트업의 주요 요원으로서 원활하게 사회 생활을 할 수 있도록 많은 점을 배우고 싶습니다', '                                               글자수\\xa0617자1,068Byte']}, 'Q2': {'[직무역량: 회원관리, 이미 실무 준비는 끝났습니다]': ['대학 시절 서비스 업종에서 다양한 아르바이트를 하며 커뮤니케이션 스킬을 쌓았습니다', '저는 특히 두 가지 경험을 통해 직방 회원관리팀에서 빠르게 업무 매뉴얼을 숙지하고 실무에 투입할 자신이 있습니다.', '', '', '', '첫째, 주문대행서비스 OOO에서 가맹업체를 담당하는 업무를 하며 직방 회원관리팀에서 하는 업무와 비슷한 실무경험을 했습니다.', '', '', '', '제가 속했던 OOO Editorial Team은 OOO에 비가맹된 업체의 정보를 탐색, 가맹을 권유하는 업무를 하거나 가맹업체의 메뉴나 가격을 수정하는 업무를 담당했습니다', '입사 후 비가맹 정보 탐색 팀에서 일했던 저는, 성실한 근무 태도로 3주 만에 가맹업체 팀으로 업무를 변경했습니다', '이후 남은 근무 기간 꾸준히 가맹업체를 담당하며 OOO의 회원 관리에 도움을 줬습니다.', '', '', '', '이런 업무를 처음 해보는 제가 수월하게 일을 할 수 있었던 데는 적절한 공감 능력이 있었기 때문입니다', '메뉴나 가격을 수정하기 위해서는 기본적으로 업체 사장님들과 한 번 이상 통화를 하게 되는데, 이 과정에서 막무가내로 요구 사항을 들어달라는 사장님들이 있으셨습니다', '저는 회사와 가맹업체의 중재자로서 원활하게 상황을 해결해야 할 의무가 있어서 사장님들의 의견을 들으면서도 최대한 OOO의 방향성을 잃지 않기 위해 노력했습니다', '사장님의 의견을 존중하면서 저만의 컨설팅을 하니 수월하게 회원 관리가 되었습니다.', '', '', '', '둘째, 교내 패스트푸드점에서 점장 대행으로 일하며 이해관계자를 관리하는 역량을 길렀습니다.', '', '올해 초, 3년 반 동안 일한 곳에서 성실성을 인정받아 점장 대행으로 근무했습니다', '6개월이라는 근무 기간 고객 컴플레인, 거래처, 직원, 매출, 위생 등 전반적인 매장 관리를 했습니다.', '', '특히 거래처와의 소통 과정에서 쌓은 역량이 직방 회원관리팀에서 도움을 줄 것으로 확신합니다', '거래처와의 소통에 문제가 생겨 발주에 차질이 생기면 가장 큰 불편을 느끼는 이해관계자는 고객이기 때문에 무엇보다 원활하게 거래처와 소통하여 발주에 문제가 없도록 했습니다.', '', '', '', '이처럼 최종 수요자인 고객에게 만족을 주기 위해 가맹업체, 거래처와의 유연한 소통에 힘썼습니다', '이는 직방 유저에게 최상의 만족을 제공하기 위해 노력해야 하는 회원관리팀원이 가져야 할 역량 중 하나라고 생각합니다', '저는 이를 사회 경험을 통해 쌓았고, 업무를 숙지하고 실무에 투입할 자신이 있습니다.', '글자수\\xa01,166자1,989Byte', '']}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crawl_jobkorea()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('다시 실행시켜 주세요.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = get_source('직방')\n",
    "# source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jobkorea.co.kr/company/1866128'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_url = get_company_url(source)\n",
    "company_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'지원동기 및 입사후 포부': '192743', '[지원 동기: 함께하고 싶습니다]': '167157'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_dict = get_assay_dict(company_url)\n",
    "assay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200334&Part_Code=0&Search_Order=1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_str = '/company/1623930/PassAssay/View?Job_Epil_No=200334&Part_Code=0&Search_Order=1&Page=1'\n",
    "\n",
    "result = re.search('Job_Epil_No=(.*)&', test_str)\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': '지원동기 및 입사후 포부',\n",
       " 'Index': ['Q1. 지원동기 및 입사후 포부', 'Q2. 성장과정', 'Q3. 성격의장단점'],\n",
       " 'Q1': {'지원동기 및 입사후 포부': ['(주)직방은 골드만삭스의 3,300만 달러 투자로 부동산 O2O 기업에서의 가치를 인정받은 탄탄한 기업입니다',\n",
       "   '더불어 헛걸음보상제, 매물광고 실명제 등을 실행함으로써 이용자들의 신뢰를 받아 부동산정보서비스 1위를 달성, 지켜가고 있습니다',\n",
       "   '또한 집을 라이프스타일의 관점에서 바라보며 살 공간을 찾는 사람들의 시간과 비용을 줄여주어 더 편리하게 찾을 수 있도록 도와주고 있습니다',\n",
       "   '첫째, 꼼꼼히 일하겠습니다',\n",
       "   '(주)직방은 신뢰를 보내주는 많은 사람 덕분에 부동산서비스 어플 1위로 80%이상이 사용하고 있습니다',\n",
       "   '자료 수집, 검수 등의 작업을 꼼꼼히 하여 믿을 수 있는 매물정보 제공, 믿을 수 있는 직방 이라는 목표를 달성하겠습니다',\n",
       "   '두번째, 콘텐츠 기획을 위해 타운홀미팅을 적극 활용하겠습니다',\n",
       "   '수요일에 열리는 전체 미팅에서 많은 지식과 아이디어를 배우고 직방이용자,임대인,부동산시장에서 필요한 콘텐츠를 기획하겠습니다',\n",
       "   '마지막으로 매월 지급되는 자기계발비로 부동산 관련 지식 공부를 하는것에 투자하겠습니다',\n",
       "   '또한 주택관리사 자격증을 1년이내에 취득하여 보다 전문적인 사원이 될것을 약속드립니다']},\n",
       " 'Q2': {'성장과정': ['중학교 수련회때였습니다',\n",
       "   '체력 극기 훈련 중이였는데 5단계를 모두 극복하면 상을 주겠다는 교관의 약속에 모든 학생이 체력 단련 훈련을 하고 있었습니다',\n",
       "   '1단계, 2단계.',\n",
       "   '단계가 올라갈수록 학생들은 난이도 높은 훈련에 포기를 선언했고 저는 4단계까지 버텼지만 5단계는 포기하기로 마음먹었습니다',\n",
       "   '교관은 5단계로 가기를 포기한 사람들에게 말했습니다',\n",
       "   ' \"사실 이 훈련은 4단계가 끝입니다',\n",
       "   '5단계에 도전하고자 남은 3명이 승리자입니다',\n",
       "   '4단계까지 버티고 5단계를 도전하지 않은 사람들은 앞으로 \"한번 더 해보자\" 는 마음을 가지고 끈기와 인내심으로 도전했으면 합니다',\n",
       "   '노력해도 오르지 않던 수학점수도 \"한번 더\" 풀어보자, 다시 공식을 외워보자, 마음을 다잡으로 노력한 끝에 70점대에서 90점대로 올렸고, 대학생 때는 공모전 대회에서 100여명앞에서 발표해야 하는 큰 대회가 있었는데 많은사람들 앞에서 발표한다는 두려움도 \"한번 더\" 리허설 연습해보자, 대본 읽어보자, 말하기 연습하자 라고 다짐하여 성공적으로 수행할 수 있었습니다',\n",
       "   '이러한 \"한 번 더\" 라는 마음이 지금의 제게 있어 시련과 어려움도 극복할 수 있는 용기가 되어주고 있습니다']},\n",
       " 'Advice': ('2',\n",
       "  ['흔히 볼 수 있는 소재, 내용, 구성이었다는 점이 아쉬운 자기소개서입니다',\n",
       "   '나름대로 성실히 작성하려고 노력한 흔적은 보이지만 지원하는 회사의 특징, 직무의 특징에 맞춰진 내용은 아닙니다',\n",
       "   '현재 내용을 긍정적으로 본다면 솔직 담백하게 쓴 내용이라는 평가를 받을 것이고, 냉정한 시선으로 본다면 불필요한 내용을 구구절절 쓴 듯한 느낌입니다',\n",
       "   '자기소개서는 전략이 중요합니다',\n",
       "   '우선 행정학을 전공한 지원자가 왜 O2O 사업을 하는 회사에 관심을 가졌는지를 제시해야 하며, 기획 직무를 희망하는 이유도 논리적으로 제시되어야 합니다',\n",
       "   '현재 내용은 단순히 자신의 경험을 제시하는 정도의 내용입니다',\n",
       "   '지원하는 회사와 직무를 고려하여 그에 맞게 전략적으로 작성한 내용이 아닙니다',\n",
       "   '이는 호감 가는 내용이 아니라는 뜻입니다.'])}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jobkorea.co.kr/company/1866128/PassAssay/View?Job_Epil_No=192743'\n",
    "\n",
    "de = get_assay_detail('https://www.jobkorea.co.kr/company/1866128', ('지원동기 및 입사후 포부', '192743'))\n",
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'지원동기 및 입사후 포부': []},\n",
       " {'성장과정': ['노력해도 오르지 않던 수학점수도 \"한번 더\" 풀어보자, 다시 공식을 외워보자, 마음을 다잡으로 노력한 끝에 70점대에서 90점대로 올렸고, 대학생 때는 공모전 대회에서 100여명앞에서 발표해야 하는 큰 대회가 있었는데 많은사람들 앞에서 발표한다는 두려움도 \"한번 더\" 리허설 연습해보자, 대본 읽어보자, 말하기 연습하자 라고 다짐하여 성공적으로 수행할 수 있었습니다. 이러한 \"한 번 더\" 라는 마음이 지금의 제게 있어 시련과 어려움도 극복할 수 있는 용기가 되어주고 있습니다.  좋은점 1']}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 안 쓰는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_page(source: BeautifulSoup) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아 회사 검색 결과 페이지에서 가장 상단에 있는 회사의 페이지를 반환하는 함수\n",
    "    source: 잡코리아 회사 검색 결과 페이지\n",
    "    company_page: 잡코리아 회사 정보 페이지, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    corp_info = source.find('div', {'class': 'corp-info'})\n",
    "    corp_list = corp_info.find_all('li', {'class': 'list-post'})\n",
    "\n",
    "    for corp in corp_list:\n",
    "        try:\n",
    "            corp_tag = corp.find('a', {'class': 'name'})\n",
    "            corp_url = 'https://www.jobkorea.co.kr' + corp_tag.get('href')\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    web = requests.get(corp_url).content\n",
    "    company_page = BeautifulSoup(web, 'html.parser')\n",
    "    \n",
    "    return company_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_page(url: BeautifulSoup) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아 회사 정보 페이지에서 합격자소서 페이지를 반환하는 함수\n",
    "    source: 잡코리아 회사 정보 페이지\n",
    "    letter_page: 합격자소서 페이지, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    company_nav = source.find('div', {'class': 'company-nav'})\n",
    "    nav_items = company_nav.find_all('a', {'class': 'company-nav-item'})\n",
    "\n",
    "    for nav_item in nav_items:\n",
    "        if nav_item.get_text() == '합격자소서':\n",
    "            letter_url = 'https://www.jobkorea.co.kr' + nav_item.get('href')\n",
    "    \n",
    "    web = requests.get(letter_url).content\n",
    "    letter_page = BeautifulSoup(web, 'html.parser')\n",
    "    \n",
    "    return letter_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
