{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잡코리아 데이터 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(company: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아에서 회사 이름에 대한 검색 결과 페이지를 반환하는 함수\n",
    "    company: 잡코리아에서 검색할 회사 이름\n",
    "    source: 잡코리아 회사 검색 결과 페이지, 함수 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://www.jobkorea.co.kr/Search/?stext={company}&tabType=corp'\n",
    "    \n",
    "    web = requests.get(url).content\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_url(source: BeautifulSoup) -> str:\n",
    "    \"\"\"\n",
    "    잡코리아 회사 검색 결과 페이지에서 가장 상단에 있는 회사의 페이지 주소를 반환하는 함수\n",
    "    source: 잡코리아 회사 검색 결과 페이지\n",
    "    company_url: 잡코리아 회사 정보 페이지 주소, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    corp_info = source.find('div', {'class': 'corp-info'})\n",
    "    corp_list = corp_info.find('li', {'class': 'list-post'})\n",
    "    corp_name = corp_list.find('a', {'class': 'name'})\n",
    "\n",
    "    company_url = 'https://www.jobkorea.co.kr' + corp_name.get('href')\n",
    "\n",
    "    return company_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assay_dict(company_url: str) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 자소서 목록을 반환하는 함수\n",
    "    url: 잡코리아 회사 정보 페이지 주소\n",
    "    assay_dict: {'자소서 제목': '자소서 페이지 번호'}, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    assay_url = company_url + '/PassAssay'\n",
    "    \n",
    "    web = requests.get(assay_url).content\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "\n",
    "    assay_dict = dict()\n",
    "\n",
    "    assay_div = source.find('div', {'class': 'passassayCont'})\n",
    "    \n",
    "    try:\n",
    "        assay_list = assay_div.find_all('li', {'class': 'assay'})\n",
    "    except AttributeError:\n",
    "        return assay_dict\n",
    "\n",
    "    for assay in assay_list:\n",
    "        assay_title = assay.find('h2', {'class': 'tit'}).get_text().strip()\n",
    "        assay_url = assay.find('a').get('href').split('&Part_Code=')[0]\n",
    "        assay_number = assay_url.split('Job_Epil_No=')[1]\n",
    "        assay_dict[assay_title] = assay_number\n",
    "\n",
    "    return assay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assay_detail(company_url: str, assay_info: tuple) -> dict:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지의 모든 내용을 반환하는 함수\n",
    "    assay_detail: 합격자소서 페이지의 모든 내용을 담은 딕셔너리, 반환값\n",
    "\n",
    "    !!! 에러 발생 !!!\n",
    "    합격자소서 페이지 요청 시 body가 자바스크립트 코드 안에 포함되어 반환\n",
    "    클래스가 detailView인 article 태그를 찾아낼 수 없음\n",
    "    \"\"\"\n",
    "\n",
    "    assay_title = assay_info[0]\n",
    "    assay_number = assay_info[1]\n",
    "    assay_detail = {'Title': assay_title}\n",
    "\n",
    "    url = company_url + f'/PassAssay/View?Job_Epil_No={assay_number}'\n",
    "    \n",
    "    web = requests.get(url).content\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "\n",
    "    detail_view = source.find('article', {'class': 'detailView'})\n",
    "\n",
    "    assay_detail['Index'] = get_assay_index(detail_view)\n",
    "\n",
    "    qna_contents = get_qna_contents(detail_view)\n",
    "\n",
    "    for i in range(len(qna_contents)):\n",
    "        assay_detail[f'Q{i+1}'] = qna_contents[i]\n",
    "\n",
    "    try:\n",
    "        assay_detail['Advice'] = get_advice_contents(detail_view)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    return assay_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assay_index(detail_view: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 목차 목록을 반환하는 함수\n",
    "    index_list: 합격자소서 페이지의 목차 목록, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    index_div = detail_view.find('div', {'class': 'bx'})\n",
    "    \n",
    "    index_li = index_div.find_all('li')\n",
    "    index_list = [index.get_text().strip() for index in index_li]\n",
    "    \n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qna_contents(detail_view: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 목차 목록을 반환하는 함수\n",
    "    qna_contents: 합격자소서 페이지의 질문과 답변, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    qna_div = detail_view.find('div', {'class': 'selfQnaWrap'})\n",
    "    qna_titles = qna_div.find_all('dt', {'class': 'on'})\n",
    "    qna_shows = qna_div.find_all('dd', {'class': 'show'})\n",
    "    qna_contents = []\n",
    "\n",
    "    for qna_title, qna_show in zip(qna_titles, qna_shows):\n",
    "        qna_title = qna_title.find('span', {'class': 'tx'}).get_text()\n",
    "        qna_lines = qna_show.find_all('b')\n",
    "        if not qna_lines:\n",
    "            qna_lines = qna_show.find('div', {'class': 'tx'})\n",
    "\n",
    "        lines = []\n",
    "        for qna_line in qna_lines:\n",
    "            lines += re.split('\\.\\s', qna_line.get_text().strip())\n",
    "        qna_lines = lines\n",
    "\n",
    "        # qna_lines = []\n",
    "        # for line in lines:\n",
    "        #     if not any(x not in line for x in ['좋은점', '아쉬운점', '글자수']):\n",
    "        #         qna_lines.append(line)\n",
    "        \n",
    "        qna_contents.append({qna_title: qna_lines})\n",
    "    \n",
    "    return qna_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advice_contents(detail_view: BeautifulSoup) -> tuple:\n",
    "    \"\"\"\n",
    "    잡코리아 합격자소서 페이지에서 총평 내용을 반환하는 함수\n",
    "    advice_contents: 합격자소서 페이지의 총평 내용, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    advice_div = detail_view.find('div', {'class': 'adviceTotal'})\n",
    "\n",
    "    # advice_title = advice_div.find('h4', {'class': 'tit'}).get_text().strip()    \n",
    "    advice_grade = advice_div.find('span', {'class': 'grade'}).get_text().strip()\n",
    "\n",
    "    advice_lines = advice_div.find('p', {'class': 'tx'}).get_text()\n",
    "    advice_lines = advice_lines.replace(' \\r\\n\\r\\n', ' ')\n",
    "    advice_lines = advice_lines.replace('\\r\\n\\r\\n', ' ')\n",
    "    advice_lines = re.split('\\.\\s', advice_lines)\n",
    "    \n",
    "    return advice_grade, advice_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_assay(original_dict: dict) -> tuple:\n",
    "    \"\"\"\n",
    "    딕셔너리에서 하나의 키값을 선택해서 해당 키와 값을 반환하는 함수\n",
    "    assay_dict: {'자소서 제목': '자소서 페이지 번호'}\n",
    "    select_page: {'인덱스': ('자소서 제목', '자소서 페이지 번호')}, 반환값\n",
    "    \"\"\"\n",
    "    \n",
    "    assay_dict = original_dict.copy()\n",
    "    index, selection = 1, None\n",
    "\n",
    "    while True:\n",
    "        select_page = dict()\n",
    "\n",
    "        try:\n",
    "            for i in range(10):\n",
    "                select_page[index] = assay_dict.popitem()\n",
    "                index += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        for idx, assay in select_page.items():\n",
    "            print(f'{idx}. {assay[0]}')\n",
    "        \n",
    "        if assay_dict:\n",
    "            print('다음 페이지로 이동(n)')\n",
    "            selection = input('목록을 선택해주세요. ')\n",
    "            if selection == 'n':\n",
    "                continue\n",
    "            return select_page[int(selection)]\n",
    "        else:\n",
    "            print('마지막 페이지 입니다.')\n",
    "            selection = input('목록을 선택해주세요. ')\n",
    "            return select_page[int(selection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_jobkorea():\n",
    "    \"\"\"\n",
    "    잡코리아 크롤링 실행 함수\n",
    "    현재 반환값: assay_detail\n",
    "    \"\"\"\n",
    "\n",
    "    company = input('회사 이름을 입력하세요. ')\n",
    "\n",
    "    try:\n",
    "        source = get_source(company)\n",
    "        company_url = get_company_url(source)\n",
    "    except AttributeError or ConnectionError:\n",
    "        raise Exception('회사 이름이 올바르지 않습니다.')\n",
    "    \n",
    "    assay_dict = get_assay_dict(company_url)\n",
    "\n",
    "    if not assay_dict:\n",
    "        print('합격자소서가 없습니다.')\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        selection = select_assay(assay_dict)\n",
    "    except KeyError or ValueError:\n",
    "        raise Exception('잘못된 번호를 입력하셨습니다.')\n",
    "    \n",
    "    assay_detail = get_assay_detail(company_url, selection)\n",
    "    print(assay_detail)\n",
    "    \n",
    "    # 작성 중"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "합격자소서가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crawl_jobkorea()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('다시 실행시켜 주세요.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = get_source('직방')\n",
    "# source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jobkorea.co.kr/company/1866128'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_url = get_company_url(source)\n",
    "company_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'지원동기 및 입사후 포부': '192743', '[지원 동기: 함께하고 싶습니다]': '167157'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assay_dict = get_assay_dict(company_url)\n",
    "assay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200334&Part_Code=0&Search_Order=1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_str = '/company/1623930/PassAssay/View?Job_Epil_No=200334&Part_Code=0&Search_Order=1&Page=1'\n",
    "\n",
    "result = re.search('Job_Epil_No=(.*)&', test_str)\n",
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': '지원동기 및 입사후 포부',\n",
       " 'Index': ['Q1. 지원동기 및 입사후 포부', 'Q2. 성장과정', 'Q3. 성격의장단점'],\n",
       " 'Q1': {'지원동기 및 입사후 포부': ['(주)직방은 골드만삭스의 3,300만 달러 투자로 부동산 O2O 기업에서의 가치를 인정받은 탄탄한 기업입니다',\n",
       "   '더불어 헛걸음보상제, 매물광고 실명제 등을 실행함으로써 이용자들의 신뢰를 받아 부동산정보서비스 1위를 달성, 지켜가고 있습니다',\n",
       "   '또한 집을 라이프스타일의 관점에서 바라보며 살 공간을 찾는 사람들의 시간과 비용을 줄여주어 더 편리하게 찾을 수 있도록 도와주고 있습니다',\n",
       "   '첫째, 꼼꼼히 일하겠습니다',\n",
       "   '(주)직방은 신뢰를 보내주는 많은 사람 덕분에 부동산서비스 어플 1위로 80%이상이 사용하고 있습니다',\n",
       "   '자료 수집, 검수 등의 작업을 꼼꼼히 하여 믿을 수 있는 매물정보 제공, 믿을 수 있는 직방 이라는 목표를 달성하겠습니다',\n",
       "   '두번째, 콘텐츠 기획을 위해 타운홀미팅을 적극 활용하겠습니다',\n",
       "   '수요일에 열리는 전체 미팅에서 많은 지식과 아이디어를 배우고 직방이용자,임대인,부동산시장에서 필요한 콘텐츠를 기획하겠습니다',\n",
       "   '마지막으로 매월 지급되는 자기계발비로 부동산 관련 지식 공부를 하는것에 투자하겠습니다',\n",
       "   '또한 주택관리사 자격증을 1년이내에 취득하여 보다 전문적인 사원이 될것을 약속드립니다']},\n",
       " 'Q2': {'성장과정': ['중학교 수련회때였습니다',\n",
       "   '체력 극기 훈련 중이였는데 5단계를 모두 극복하면 상을 주겠다는 교관의 약속에 모든 학생이 체력 단련 훈련을 하고 있었습니다',\n",
       "   '1단계, 2단계.',\n",
       "   '단계가 올라갈수록 학생들은 난이도 높은 훈련에 포기를 선언했고 저는 4단계까지 버텼지만 5단계는 포기하기로 마음먹었습니다',\n",
       "   '교관은 5단계로 가기를 포기한 사람들에게 말했습니다',\n",
       "   ' \"사실 이 훈련은 4단계가 끝입니다',\n",
       "   '5단계에 도전하고자 남은 3명이 승리자입니다',\n",
       "   '4단계까지 버티고 5단계를 도전하지 않은 사람들은 앞으로 \"한번 더 해보자\" 는 마음을 가지고 끈기와 인내심으로 도전했으면 합니다',\n",
       "   '노력해도 오르지 않던 수학점수도 \"한번 더\" 풀어보자, 다시 공식을 외워보자, 마음을 다잡으로 노력한 끝에 70점대에서 90점대로 올렸고, 대학생 때는 공모전 대회에서 100여명앞에서 발표해야 하는 큰 대회가 있었는데 많은사람들 앞에서 발표한다는 두려움도 \"한번 더\" 리허설 연습해보자, 대본 읽어보자, 말하기 연습하자 라고 다짐하여 성공적으로 수행할 수 있었습니다',\n",
       "   '이러한 \"한 번 더\" 라는 마음이 지금의 제게 있어 시련과 어려움도 극복할 수 있는 용기가 되어주고 있습니다']},\n",
       " 'Advice': ('2',\n",
       "  ['흔히 볼 수 있는 소재, 내용, 구성이었다는 점이 아쉬운 자기소개서입니다',\n",
       "   '나름대로 성실히 작성하려고 노력한 흔적은 보이지만 지원하는 회사의 특징, 직무의 특징에 맞춰진 내용은 아닙니다',\n",
       "   '현재 내용을 긍정적으로 본다면 솔직 담백하게 쓴 내용이라는 평가를 받을 것이고, 냉정한 시선으로 본다면 불필요한 내용을 구구절절 쓴 듯한 느낌입니다',\n",
       "   '자기소개서는 전략이 중요합니다',\n",
       "   '우선 행정학을 전공한 지원자가 왜 O2O 사업을 하는 회사에 관심을 가졌는지를 제시해야 하며, 기획 직무를 희망하는 이유도 논리적으로 제시되어야 합니다',\n",
       "   '현재 내용은 단순히 자신의 경험을 제시하는 정도의 내용입니다',\n",
       "   '지원하는 회사와 직무를 고려하여 그에 맞게 전략적으로 작성한 내용이 아닙니다',\n",
       "   '이는 호감 가는 내용이 아니라는 뜻입니다.'])}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jobkorea.co.kr/company/1866128/PassAssay/View?Job_Epil_No=192743'\n",
    "\n",
    "de = get_assay_detail('https://www.jobkorea.co.kr/company/1866128', ('지원동기 및 입사후 포부', '192743'))\n",
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'지원동기 및 입사후 포부': []},\n",
       " {'성장과정': ['노력해도 오르지 않던 수학점수도 \"한번 더\" 풀어보자, 다시 공식을 외워보자, 마음을 다잡으로 노력한 끝에 70점대에서 90점대로 올렸고, 대학생 때는 공모전 대회에서 100여명앞에서 발표해야 하는 큰 대회가 있었는데 많은사람들 앞에서 발표한다는 두려움도 \"한번 더\" 리허설 연습해보자, 대본 읽어보자, 말하기 연습하자 라고 다짐하여 성공적으로 수행할 수 있었습니다. 이러한 \"한 번 더\" 라는 마음이 지금의 제게 있어 시련과 어려움도 극복할 수 있는 용기가 되어주고 있습니다.  좋은점 1']}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 안 쓰는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_page(source: BeautifulSoup) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아 회사 검색 결과 페이지에서 가장 상단에 있는 회사의 페이지를 반환하는 함수\n",
    "    source: 잡코리아 회사 검색 결과 페이지\n",
    "    company_page: 잡코리아 회사 정보 페이지, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    corp_info = source.find('div', {'class': 'corp-info'})\n",
    "    corp_list = corp_info.find_all('li', {'class': 'list-post'})\n",
    "\n",
    "    for corp in corp_list:\n",
    "        try:\n",
    "            corp_tag = corp.find('a', {'class': 'name'})\n",
    "            corp_url = 'https://www.jobkorea.co.kr' + corp_tag.get('href')\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    web = requests.get(corp_url).content\n",
    "    company_page = BeautifulSoup(web, 'html.parser')\n",
    "    \n",
    "    return company_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_page(url: BeautifulSoup) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    잡코리아 회사 정보 페이지에서 합격자소서 페이지를 반환하는 함수\n",
    "    source: 잡코리아 회사 정보 페이지\n",
    "    letter_page: 합격자소서 페이지, 반환값\n",
    "    \"\"\"\n",
    "\n",
    "    company_nav = source.find('div', {'class': 'company-nav'})\n",
    "    nav_items = company_nav.find_all('a', {'class': 'company-nav-item'})\n",
    "\n",
    "    for nav_item in nav_items:\n",
    "        if nav_item.get_text() == '합격자소서':\n",
    "            letter_url = 'https://www.jobkorea.co.kr' + nav_item.get('href')\n",
    "    \n",
    "    web = requests.get(letter_url).content\n",
    "    letter_page = BeautifulSoup(web, 'html.parser')\n",
    "    \n",
    "    return letter_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
